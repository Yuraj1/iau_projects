{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "observation = pd.read_csv(\"./094/observation.csv\", sep='\\t', engine=\"python\")",
   "id": "81474f572c09048a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = observation['oximetry'].values\n",
    "X = observation.drop(columns=['oximetry'], axis=1).values\n",
    "feature_names = observation.drop(columns=['oximetry'], axis=1).columns"
   ],
   "id": "23f13136932ac1d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "quantile_features = [20, 13]\n",
    "scaled_features = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21]\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=42, n_quantiles=2)\n",
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ],
   "id": "142404ef81e59605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "id": "676d93ca7ffdc985",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imputer.fit(X_train)\n",
    "\n",
    "X_train_imp = imputer.transform(X_train)\n",
    "X_test_imp  = imputer.transform(X_test)\n",
    "\n",
    "qt.fit(X_train_imp[quantile_features])\n",
    "scaler.fit(X_train_imp[scaled_features])\n",
    "\n",
    "X_train_tr = X_train_imp.copy()\n",
    "X_test_tr  = X_test_imp.copy()\n",
    "\n",
    "X_train_tr[quantile_features] = qt.transform(X_train_imp[quantile_features])\n",
    "X_test_tr[quantile_features]  = qt.transform(X_test_imp[quantile_features])\n",
    "\n",
    "X_train_tr[scaled_features] = scaler.transform(X_train_imp[scaled_features])\n",
    "X_test_tr[scaled_features]  = scaler.transform(X_test_imp[scaled_features])"
   ],
   "id": "1b3d2cb5b4770048",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "ca106481c7e71e8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "results = []\n",
    "\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision (macro):\", precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    print(\"Recall (macro):   \", recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "    print()\n",
    "\n",
    "def evaluate_model(name, y_train, y_train_pred, y_test, y_test_pred, average='binary'):\n",
    "    acc_train = accuracy_score(y_train, y_train_pred)\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    prec_train = precision_score(y_train, y_train_pred, average=average)\n",
    "    prec_test = precision_score(y_test, y_test_pred, average=average)\n",
    "\n",
    "    rec_train = recall_score(y_train, y_train_pred, average=average)\n",
    "    rec_test = recall_score(y_test, y_test_pred, average=average)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy_train\": acc_train,\n",
    "        \"precision_train\": prec_train,\n",
    "        \"recall_train\": rec_train,\n",
    "        \"accuracy_test\": acc_test,\n",
    "        \"precision_test\": prec_test,\n",
    "        \"recall_test\": rec_test,\n",
    "    }"
   ],
   "id": "b990114f756ba3d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 A",
   "id": "7b8a24c53ba31399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probs = counts[counts > 0] / len(y)\n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "def information_gain(y, y_left, y_right):\n",
    "    H_before = entropy(y)\n",
    "    n = len(y)\n",
    "    H_after = (len(y_left) / n) * entropy(y_left) + (len(y_right) / n) * entropy(y_right)\n",
    "    return H_before - H_after"
   ],
   "id": "e733d8814ee94be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, *, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ],
   "id": "8d136387f1bb1e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ID3Classifier:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).astype(int)\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.root = self._grow_tree(X, y, depth=1)\n",
    "        return self\n",
    "    \n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(np.unique(y))\n",
    "\n",
    "        if (depth >= self.max_depth or \n",
    "            num_labels == 1 or \n",
    "            num_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        best_feature, best_threshold, best_gain = self._id3(X, y)\n",
    "        \n",
    "        if best_gain == 0 or best_feature is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        indices_left = X[:, best_feature] <= best_threshold\n",
    "        X_left, y_left = X[indices_left], y[indices_left]\n",
    "        X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "        left_child = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_child = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return TreeNode(feature_index=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "    def _id3(self, X, y):\n",
    "        best_gain = 0.0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            X_column = X[:, feature_index]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X_column <= threshold\n",
    "                right_indices = X_column > threshold\n",
    "\n",
    "                if left_indices.sum() == 0 or right_indices.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                y_left, y_right = y[left_indices], y[right_indices]\n",
    "                gain = information_gain(y, y_left, y_right)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_gain\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._predict(x, self.root) for x in X])\n",
    "\n",
    "    def _predict(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict(x, node.left)\n",
    "        else:\n",
    "            return self._predict(x, node.right)"
   ],
   "id": "196077b52157a35f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "id3 = ID3Classifier(max_depth=6, min_samples_split=2)\n",
    "id3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = id3.predict(X_train_tr)\n",
    "y_pred_test = id3.predict(X_test_tr)"
   ],
   "id": "e142040eb4089b47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "max_depth=3, min_samples_split=2 => train_acc=0.806, test_acc=0.798\n",
    "\n",
    "max_depth=3, min_samples_split=5 => train_acc=0.806, test_acc=0.798\n",
    "\n",
    "max_depth=3, min_samples_split=10 => train_acc=0.806, test_acc=0.798\n",
    "\n",
    "max_depth=3, min_samples_split=20 => train_acc=0.806, test_acc=0.798\n",
    "\n",
    "max_depth=4, min_samples_split=2 => train_acc=0.816, test_acc=0.817\n",
    "\n",
    "max_depth=4, min_samples_split=5 => train_acc=0.816, test_acc=0.817\n",
    "\n",
    "max_depth=4, min_samples_split=10 => train_acc=0.816, test_acc=0.817\n",
    "\n",
    "max_depth=4, min_samples_split=20 => train_acc=0.816, test_acc=0.817\n",
    "\n",
    "max_depth=5, min_samples_split=2 => train_acc=0.849, test_acc=0.843\n",
    "\n",
    "max_depth=5, min_samples_split=5 => train_acc=0.849, test_acc=0.843\n",
    "\n",
    "max_depth=5, min_samples_split=10 => train_acc=0.849, test_acc=0.843\n",
    "\n",
    "max_depth=5, min_samples_split=20 => train_acc=0.848, test_acc=0.843\n",
    "\n",
    "max_depth=6, min_samples_split=2 => train_acc=0.871, test_acc=0.865\n",
    "\n",
    "max_depth=6, min_samples_split=5 => train_acc=0.871, test_acc=0.865\n",
    "\n",
    "max_depth=6, min_samples_split=10 => train_acc=0.871, test_acc=0.865\n",
    "\n",
    "max_depth=6, min_samples_split=20 => train_acc=0.871, test_acc=0.865\n",
    "\n",
    "max_depth=8, min_samples_split=2 => train_acc=0.914, test_acc=0.889\n",
    "\n",
    "max_depth=8, min_samples_split=5 => train_acc=0.914, test_acc=0.890\n",
    "\n",
    "max_depth=8, min_samples_split=10 => train_acc=0.913, test_acc=0.889\n",
    "\n",
    "max_depth=8, min_samples_split=20 => train_acc=0.912, test_acc=0.889\n",
    "\n",
    "max_depth=10, min_samples_split=2 => train_acc=0.944, test_acc=0.904\n",
    "\n",
    "max_depth=10, min_samples_split=5 => train_acc=0.944, test_acc=0.904\n",
    "\n",
    "max_depth=10, min_samples_split=10 => train_acc=0.941, test_acc=0.902\n",
    "\n",
    "max_depth=10, min_samples_split=20 => train_acc=0.937, test_acc=0.902"
   ],
   "id": "876046e84fedf2c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 B",
   "id": "f6a5df55e65f9360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_metrics(\"ID3Classifier (Train)\",  y_train, y_pred_train)\n",
    "print_metrics(\"ID3Classifier (Test)\",  y_test, y_pred_test)\n",
    "\n",
    "results.append(\n",
    "    evaluate_model(\"ID3Classifier\", \n",
    "                   y_train, y_pred_train, \n",
    "                   y_test, y_pred_test,\n",
    "                   average='binary')\n",
    ")"
   ],
   "id": "918fcdb8570a83de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 C",
   "id": "dbc490714c979df8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Accuracy: **0.8709** − **0.8626** = **0.0083** => **0.83%**\n",
    "\n",
    "Precision: **0.8806** - **0.8683** = **0.0123** => **1.23%**\n",
    "\n",
    "Recall: **0.8538** - **0.8411** = **0.0127** => **1.27%**\n",
    "\n",
    "The differences between training and testing values are minimal (less than 2%), which means that the model does not overfit and generalizes very well to new data. We achieved this stable performance by selecting appropriate hyperparameters for the ID3 classifier: *max_depth=6, min_samples_split=2*"
   ],
   "id": "823b7b69eba68911"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 A",
   "id": "6ef1be69ed2ccd3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=6,     \n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train_tr, y_train)\n",
    "\n",
    "y_pred_dt_train = dt.predict(X_train_tr)\n",
    "y_pred_dt_test = dt.predict(X_test_tr)\n",
    "\n",
    "print_metrics(\"DecisionTreeClassifier (Train)\",  y_train, y_pred_dt_train)\n",
    "print_metrics(\"DecisionTreeClassifier (Test)\",  y_test, y_pred_dt_test)\n",
    "\n",
    "results.append(\n",
    "    evaluate_model(\"DecisionTreeClassifier\", \n",
    "                   y_train, y_pred_dt_train, \n",
    "                   y_test, y_pred_dt_test,\n",
    "                   average='binary')\n",
    ")"
   ],
   "id": "d779b1a399e8f4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 B",
   "id": "2d6704aed24b49a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_tr, y_train)\n",
    "\n",
    "y_pred_lr_train = log_reg.predict(X_train_tr)\n",
    "y_pred_lr_test = log_reg.predict(X_test_tr)\n",
    "\n",
    "print_metrics(\"LogisticRegression (Train)\",  y_train, y_pred_lr_train)\n",
    "print_metrics(\"LogisticRegression (Test)\",  y_test, y_pred_lr_test)\n",
    "\n",
    "results.append(\n",
    "    evaluate_model(\"LogisticRegression\", \n",
    "                   y_train, y_pred_lr_train, \n",
    "                   y_test, y_pred_lr_test,\n",
    "                   average='binary')\n",
    ")"
   ],
   "id": "3f288c281640e3f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 C",
   "id": "64041be4858fb7f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "DecisionTreeClassifier performed best. It is fast, well optimized, and supports splitting by numerical thresholds. ID3 performed good as well. It is slightly weaker than the scikit-learn tree, but the difference is not significant. LogisticRegression has the lowest accuracy. It is a linear model, so it cannot capture nonlinear relationships as well as trees. \n",
    "\n",
    "One more thing – speed. ID3 was the slowest of all models."
   ],
   "id": "6e31d38ae4f1f856"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 D",
   "id": "8d6669264e1f30b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt,\n",
    "    feature_names=feature_names,\n",
    "    class_names=[str(c) for c in np.unique(y_train)],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ae49837e124b61b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 E",
   "id": "7aa53633fd457c33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "id": "21c2becd6fb812a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 A",
   "id": "b85e7c74860f0f22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b8b14c3111dc4180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fc3e64b0f8528fb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "20d6c3421c8e54d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7f79d489b65a29c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c434ec43497de28a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
