{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "observation = pd.read_csv(\"./094/observation.csv\", sep='\\t', engine=\"python\")",
   "id": "22aa2bc01ba5bdba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 A",
   "id": "41b66c8e227a9c5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "8bedbfb76e071579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = observation['oximetry'].values\n",
    "x = observation.drop(columns=['oximetry'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_df = X_train.copy()\n",
    "# train_df[\"oximetry\"] = y_train\n",
    "# \n",
    "# test_df = X_test.copy()\n",
    "# test_df[\"oximetry\"] = y_test\n",
    "# \n",
    "# train_df.to_csv(\"train_raw.csv\", index=False)\n",
    "# test_df.to_csv(\"test_raw.csv\", index=False)"
   ],
   "id": "1774a2be3fceaaf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we divided our dataset into training and testing sets",
   "id": "2270d51e9da2b90e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 B",
   "id": "b3dfc352d051b635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.DataFrame(X_train)"
   ],
   "id": "a6693bd4f3a83ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check types",
   "id": "6c6c69f13fc23ff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.dtypes",
   "id": "51b2b23cb4d67f6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check nulls",
   "id": "d886cc07fe4d2e1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if X_train.isnull().sum().sum() > 0:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train = imputer.fit_transform(X_train)"
   ],
   "id": "18480706788d6059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If there are missing values here, we will replace them with the median ",
   "id": "b603b5ab49f825a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check duplicates",
   "id": "7cb942079421eebf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if X_train.duplicated().sum() > 0:\n",
    "    X_train = X_train.drop_duplicates()\n",
    "    y_train = y_train.loc[X_train.index]"
   ],
   "id": "700cded594b4a810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If there are duplicates here, we will remove them",
   "id": "51291b05a1e8419d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 C\n",
   "id": "91fd3a8fc4fc0e6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaling",
   "id": "b8f69f4de4fa554d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_mm = scaler.fit_transform(X_train) \n",
    "\n",
    "X_mm"
   ],
   "id": "9689c21d2975529f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_std = scaler.fit_transform(X_train) \n",
    "\n",
    "X_std"
   ],
   "id": "5a42dc9153876d4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"StandardScaler:\")\n",
    "print(\"Mean: \", np.mean(X_train, axis=0).round(3))\n",
    "print(\"Std: \", np.std(X_train, axis=0).round(3))\n",
    "\n",
    "print(\"\\nMinMaxScaler:\")\n",
    "print(\"Min: \", np.min(X_train, axis=0).round(3))\n",
    "print(\"Max: \", np.max(X_train, axis=0).round(3))"
   ],
   "id": "183c1adabae7b43b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"StandardScaler:\")\n",
    "print(\"Mean: \", np.mean(X_std, axis=0).round(3))\n",
    "print(\"Std: \", np.std(X_std, axis=0).round(3))\n",
    "\n",
    "print(\"\\nMinMaxScaler:\")\n",
    "print(\"Min: \", np.min(X_mm, axis=0).round(3))\n",
    "print(\"Max: \", np.max(X_mm, axis=0).round(3))"
   ],
   "id": "a4de573e391702b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After applying **StandardScaler**, the average value of each feature became close to 0, and the standard deviation became close to 1, confirming that the data was scaled correctly.\n",
    "\n",
    "After applying **MinMaxScaler**, the minimum values of the features became equal to 0, and the maximum values became equal to 1, also confirming that the normalization worked correctly."
   ],
   "id": "58b5fddbae439af3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformers",
   "id": "f3fdb7341c5d2074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.hist(X_train[0], bins=10)"
   ],
   "id": "6577cb48f9be1c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our initial histogram of the distribution of feature values",
   "id": "346e94102b4b79f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "power = PowerTransformer(method='yeo-johnson', standardize=True) \n",
    "X_pt = power.fit_transform(X_train)\n",
    "\n",
    "pyplot.hist(X_pt[0], bins=10) "
   ],
   "id": "305a8d7524ca14ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After **PowerTransformer**",
   "id": "e18986c260929614"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "power = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_qt = power.fit_transform(X_train)\n",
    "\n",
    "pyplot.hist(X_qt[0], bins=10)"
   ],
   "id": "167941ea3ca4e9b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After **QuantileTransformer**",
   "id": "8014859686527ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skews = skew(X_train, axis=0)\n",
    "\n",
    "skew_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Skewness': skews\n",
    "})\n",
    "\n",
    "skew_df"
   ],
   "id": "f1864f5873117a07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we check whether the distribution is normal",
   "id": "e23a48a6b14b49d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 D",
   "id": "782178b7cfe1e1a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We divided our dataset into **training** (80%) and **test** (20%) samples\n",
    "\n",
    "Further work was carried out only with the **training** sample\n",
    "\n",
    "We compared two approaches - **scaling** and **transformation** - and analyzed the distribution of features (checked for skew) to assess how close the data was to a normal distribution\n",
    "\n",
    "Most features had a normal distribution, but the presence of some skewed features led us to decide to use **QuantileTransformer** for subsequent data preprocessing"
   ],
   "id": "ff3e2e42e29285ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 A",
   "id": "b837891e49c00a9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Корреляционный анализ (линейная связь)",
   "id": "9e4d2ebd451b16d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_1 = observation.drop(columns=['oximetry'], axis=1)\n",
    "\n",
    "X_qt_df = pd.DataFrame(X_qt, columns=x_1.columns)\n",
    "df_corr = X_qt_df.copy()\n",
    "df_corr[\"oximetry\"] = y_train\n",
    "\n",
    "corr_matrix = df_corr.corr(numeric_only=True)\n",
    "\n",
    "corr_sorted = corr_matrix[\"oximetry\"].reindex(\n",
    "    corr_matrix[\"oximetry\"].abs().sort_values(ascending=False).index\n",
    ")\n",
    "corr_sorted"
   ],
   "id": "c8f9c3783ea41aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# sns.heatmap(corr_sorted, annot=True, cmap='coolwarm')\n",
    "sns.heatmap(corr_sorted.to_frame(name=\"Pearson r\"), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ],
   "id": "44d4411082f99da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ANOVA F-test (feature selection test)",
   "id": "53d4fc46b3375539"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "X = pd.DataFrame(X_qt, columns=x_1.columns) \n",
    "y = y_train \n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k='all')\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "idx = selector.get_support(indices=True)\n",
    "selected_features = X.columns[idx]\n",
    "\n",
    "anova_results = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'F_value': selector.scores_[idx],\n",
    "    'p_value': selector.pvalues_[idx]\n",
    "}).sort_values(by='F_value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Shape после отбора:\", X_new.shape)\n",
    "print(\"Выбранные признаки:\", list(selected_features))\n",
    "print(anova_results)"
   ],
   "id": "5cf29af2490e4851",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=anova_results, x='F_value', y='Feature')\n",
    "plt.xscale('log')\n",
    "plt.title('ANOVA F-test (log scale)')\n",
    "plt.show()"
   ],
   "id": "1feb2474b9b86394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mutual Information (нелинейная зависимость)",
   "id": "98c8d6e4473a5b2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = pd.DataFrame(X_qt, columns=x_1.columns) \n",
    "y = y_train \n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "selector.fit(X, y)\n",
    "\n",
    "scores = pd.Series(abs(selector.scores_), index=X.columns).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "scores.plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "print(scores.sort_values(ascending=False))"
   ],
   "id": "b6d45a44f12af7bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_part = (corr_sorted.drop(labels=['oximetry'], errors='ignore').abs().rename('Pearson_|r|'))\n",
    "anova_part = (anova_results.set_index('Feature')['F_value'].rename('ANOVA_F'))\n",
    "mi_part = scores.rename('Mutual_Info')\n",
    "\n",
    "all_idx = corr_part.index.union(anova_part.index).union(mi_part.index)\n",
    "\n",
    "compare_simple = pd.concat([corr_part, anova_part, mi_part], axis=1).reindex(all_idx).drop(index='oximetry', errors='ignore')\n",
    "display(compare_simple.sort_values('Pearson_|r|', ascending=False))\n",
    "\n",
    "\n",
    "def safe_minmax(series):\n",
    "    s_min, s_max = series.min(), series.max()\n",
    "    if s_max == s_min:\n",
    "        return pd.Series(0.0, index=series.index)\n",
    "    return (series - s_min) / (s_max - s_min)\n",
    "\n",
    "norm = compare_simple.apply(safe_minmax, axis=0)\n",
    "\n",
    "norm['Mean_Score'] = norm.mean(axis=1)\n",
    "\n",
    "final_display = norm.sort_values('Mean_Score', ascending=False)\n",
    "\n",
    "final_display.style.format('{:.6f}')"
   ],
   "id": "8593604a94478152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 B",
   "id": "8891a6a7b14809ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ranked_features = final_display.sort_values('Mean_Score', ascending=False).head(5).copy()\n",
    "display(ranked_features.style.format('{:.6f}'))\n",
    "\n",
    "topk = (final_display.reset_index().head(5))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=topk, x='Mean_Score', y='index')\n",
    "plt.title('Top 5')\n",
    "plt.show()"
   ],
   "id": "94505a29fea4290a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 C\n",
    "### (C-1b) Zdôvodnenie rozhodnutí pri realizácii\n",
    "\n",
    "Pri realizácii úlohy som sa rozhodol využiť tri komplementárne prístupy na hodnotenie informatívnosti atribútov:\n",
    "**Pearsonova korelácia**, **ANOVA F-test** a **Mutual Information**.  \n",
    "Tieto techniky reprezentujú tri rôzne pohľady na vzťah medzi vstupnými premennými a cieľovou premennou *oximetry*:\n",
    "\n",
    "- **Pearsonova korelácia** umožňuje zachytiť **lineárnu závislosť** medzi atribútom a cieľovou premennou.\n",
    "- **ANOVA F-test** zisťuje, či existujú **štatisticky významné rozdiely v priemeroch** medzi skupinami hodnôt a hodnotí lineárnu relevantnosť premenných.\n",
    "- **Mutual Information** je **nelineárna metóda**, ktorá kvantifikuje množstvo informácie, ktorú jeden atribút poskytuje o inom, a teda odhaľuje aj zložitejšie vzťahy.\n",
    "\n",
    "Výber týchto troch metód umožnil porovnať lineárne aj nelineárne súvislosti a získať\n",
    "robustnejší prehľad o dôležitosti atribútov.\n",
    "\n",
    "Všetky výsledky boli následne **normalizované pomocou min–max transformácie** do intervalu ⟨0, 1⟩,  \n",
    "aby bolo možné spravodlivo porovnávať hodnoty z rôznych metód, ktoré majú odlišné jednotky a rozsahy.\n",
    "Z týchto normalizovaných hodnôt bol vypočítaný **priemerný index informatívnosti (Mean Score)**,\n",
    "ktorý vyjadruje celkovú dôležitosť atribútu naprieč metódami.\n",
    "\n",
    "Týmto postupom bolo zabezpečené:\n",
    "- porovnateľnosť výsledkov z rôznych štatistických metód,\n",
    "- odstránenie vplyvu rozdielnych mierok hodnôt (napr. F-hodnoty vs. korelácia),\n",
    "- transparentný a reprodukovateľný spôsob zoradenia atribútov podľa dôležitosti.\n",
    "\n",
    "Takto spracované výsledky umožňujú jednoznačne určiť,\n",
    "ktoré atribúty majú najväčší vplyv na predikciu *oximetry*\n",
    "a sú vhodné pre ďalšiu tvorbu predikčných modelov.\n"
   ],
   "id": "55aecaeccb227a9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 A ",
   "id": "3ad9ab6629ec17ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "num_imputer.fit(X_train)\n",
    "\n",
    "X_train_imp = num_imputer.transform(X_train)\n",
    "X_test_imp  = num_imputer.transform(X_test)\n",
    "\n",
    "power = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "power.fit(X_train_imp)\n",
    "\n",
    "X_train_pt = power.transform(X_train_imp)\n",
    "X_test_pt  = power.transform(X_test_imp)"
   ],
   "id": "aa70ea344777cc0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 B\n",
   "id": "26d846f73af9ee05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    QuantileTransformer(output_distribution='normal', random_state=42),\n",
    "    Ridge(alpha=1.0, random_state=42) \n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"R^2 на тесте: {r2:.4f}\")\n",
    "\n",
    "y_pred = model.predict(X_test[:5])\n",
    "print(\"Пример предсказаний:\", y_pred)\n"
   ],
   "id": "6c66c422daa44ae8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
