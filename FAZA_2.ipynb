{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "observation = pd.read_csv(\"./094/observation.csv\", sep='\\t', engine=\"python\")",
   "id": "22aa2bc01ba5bdba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 A",
   "id": "41b66c8e227a9c5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "8bedbfb76e071579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = observation['oximetry'].values\n",
    "x = observation.drop(columns=['oximetry'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_df = X_train.copy()\n",
    "# train_df[\"oximetry\"] = y_train\n",
    "# \n",
    "# test_df = X_test.copy()\n",
    "# test_df[\"oximetry\"] = y_test\n",
    "# \n",
    "# train_df.to_csv(\"train_raw.csv\", index=False)\n",
    "# test_df.to_csv(\"test_raw.csv\", index=False)"
   ],
   "id": "1774a2be3fceaaf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we divided our dataset into training and testing sets",
   "id": "2270d51e9da2b90e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 B",
   "id": "b3dfc352d051b635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.DataFrame(X_train)"
   ],
   "id": "a6693bd4f3a83ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check types",
   "id": "6c6c69f13fc23ff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.dtypes",
   "id": "51b2b23cb4d67f6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check nulls",
   "id": "d886cc07fe4d2e1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if X_train.isnull().sum().sum() > 0:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train = imputer.fit_transform(X_train)"
   ],
   "id": "18480706788d6059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If there are missing values here, we will replace them with the median ",
   "id": "b603b5ab49f825a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check duplicates",
   "id": "7cb942079421eebf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if X_train.duplicated().sum() > 0:\n",
    "    X_train = X_train.drop_duplicates()\n",
    "    y_train = y_train.loc[X_train.index]"
   ],
   "id": "700cded594b4a810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If there are duplicates here, we will remove them",
   "id": "51291b05a1e8419d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 C\n",
   "id": "91fd3a8fc4fc0e6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaling",
   "id": "b8f69f4de4fa554d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_mm = scaler.fit_transform(X_train) \n",
    "\n",
    "X_mm"
   ],
   "id": "9689c21d2975529f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After applying **MinMaxScaler**, all features were normalized to a range from 0 to 1, providing a uniform scale for all variables",
   "id": "9f5773f6371d7878"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_std = scaler.fit_transform(X_train) \n",
    "\n",
    "X_std"
   ],
   "id": "5a42dc9153876d4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After applying **StandardScaler**, the data was standardized: each feature has a mean value of 0 and a standard deviation of 1",
   "id": "3f623574a9f0aace"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"StandardScaler:\")\n",
    "print(\"Mean: \", np.mean(X_train, axis=0).round(3))\n",
    "print(\"Std: \", np.std(X_train, axis=0).round(3))\n",
    "\n",
    "print(\"\\nMinMaxScaler:\")\n",
    "print(\"Min: \", np.min(X_train, axis=0).round(3))\n",
    "print(\"Max: \", np.max(X_train, axis=0).round(3))"
   ],
   "id": "183c1adabae7b43b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"StandardScaler:\")\n",
    "print(\"Mean: \", np.mean(X_std, axis=0).round(3))\n",
    "print(\"Std: \", np.std(X_std, axis=0).round(3))\n",
    "\n",
    "print(\"\\nMinMaxScaler:\")\n",
    "print(\"Min: \", np.min(X_mm, axis=0).round(3))\n",
    "print(\"Max: \", np.max(X_mm, axis=0).round(3))"
   ],
   "id": "a4de573e391702b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After applying **StandardScaler**, the average value of each feature became close to 0, and the standard deviation became close to 1, confirming that the data was scaled correctly.\n",
    "\n",
    "After applying **MinMaxScaler**, the minimum values of the features became equal to 0, and the maximum values became equal to 1, also confirming that the normalization worked correctly."
   ],
   "id": "58b5fddbae439af3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformers",
   "id": "f3fdb7341c5d2074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.hist(X_train[0], bins=10)"
   ],
   "id": "6577cb48f9be1c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our initial histogram of the distribution of feature values",
   "id": "346e94102b4b79f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "power = PowerTransformer(method='yeo-johnson', standardize=True) \n",
    "X_pt = power.fit_transform(X_train)\n",
    "\n",
    "pyplot.hist(X_pt[0], bins=10) "
   ],
   "id": "305a8d7524ca14ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After **PowerTransformer**",
   "id": "e18986c260929614"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "power = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_qt = power.fit_transform(X_train)\n",
    "\n",
    "pyplot.hist(X_qt[0], bins=10)"
   ],
   "id": "167941ea3ca4e9b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After **QuantileTransformer**",
   "id": "8014859686527ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skews = skew(X_train, axis=0)\n",
    "\n",
    "skew_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Skewness': skews\n",
    "})\n",
    "\n",
    "skew_df"
   ],
   "id": "f1864f5873117a07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The results show that most features have a distribution close to normal, but two features have a skewness value > 1, indicating their strong asymmetry. This means that the distribution of these features is asymmetrical.",
   "id": "e23a48a6b14b49d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 D",
   "id": "782178b7cfe1e1a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We divided our dataset into **training** (80%) and **test** (20%) samples\n",
    "\n",
    "Further work was carried out only with the **training** sample\n",
    "\n",
    "We compared two approaches - **scaling** and **transformation** - and analyzed the distribution of features (checked for skew) to assess how close the data was to a normal distribution\n",
    "\n",
    "Most features had a normal distribution, but the presence of some skewed features led us to decide to use **QuantileTransformer** for subsequent data preprocessing"
   ],
   "id": "ff3e2e42e29285ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 A",
   "id": "b837891e49c00a9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Correlation analysis (linear relationship)",
   "id": "9e4d2ebd451b16d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_1 = observation.drop(columns=['oximetry'], axis=1)\n",
    "\n",
    "X_qt_df = pd.DataFrame(X_qt, columns=x_1.columns)\n",
    "df_corr = X_qt_df.copy()\n",
    "df_corr[\"oximetry\"] = y_train\n",
    "\n",
    "corr_matrix = df_corr.corr(numeric_only=True)\n",
    "\n",
    "corr_sorted = corr_matrix[\"oximetry\"].reindex(corr_matrix[\"oximetry\"].abs().sort_values(ascending=False).index)\n",
    "corr_sorted"
   ],
   "id": "c8f9c3783ea41aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Calculation of correlation between attributes and target variable\n",
    "Pearson's correlation was calculated to assess the linear relationship between variables.\n",
    "Before calculation, the input data was standardized (X_qt). \n",
    "The target variable **oximetry** was temporarily added to the dataset to calculate the correlation coefficients between it and the other attributes. \n",
    "The attributes were then sorted by absolute correlation value in descending order, identifying the most significant variables."
   ],
   "id": "293a80d8c747a8ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# sns.heatmap(corr_sorted, annot=True, cmap='coolwarm')\n",
    "sns.heatmap(corr_sorted.to_frame(name=\"Pearson r\"), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ],
   "id": "44d4411082f99da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ANOVA F-test",
   "id": "53d4fc46b3375539"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = pd.DataFrame(X_qt, columns=x_1.columns)\n",
    "y = y_train\n",
    "\n",
    "scores, pvals = f_regression(X, y)\n",
    "\n",
    "anova_results = (\n",
    "    pd.DataFrame({'Feature': X.columns, 'F_value': scores, 'p_value': pvals})\n",
    "      .sort_values('F_value', ascending=False, ignore_index=True)\n",
    ")\n",
    "\n",
    "print(anova_results)"
   ],
   "id": "5cf29af2490e4851",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Selecting attributes using the ANOVA F-test\n",
    "The **f_regression** test was used to assess the linear relationship between individual attributes and the target variable **oximetry**.  \n",
    "For each attribute, the value of the **F-statistic** and the corresponding **p-values** are calculated separately, which show how strongly the attribute is related to the target variable.  \n",
    "Higher F values and lower p-values mean that the attribute has a greater influence on the target variable."
   ],
   "id": "54baece29b4f2d6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=anova_results, x='F_value', y='Feature')\n",
    "plt.xscale('log')\n",
    "plt.title('ANOVA F-test (log)')\n",
    "plt.show()"
   ],
   "id": "1feb2474b9b86394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mutual Information (non-linear dependence)",
   "id": "98c8d6e4473a5b2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = pd.DataFrame(X_qt, columns=x_1.columns) \n",
    "y = y_train \n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "selector.fit(X, y)\n",
    "\n",
    "scores = pd.Series(abs(selector.scores_), index=X.columns).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "scores.plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "print(scores.sort_values(ascending=False))"
   ],
   "id": "b6d45a44f12af7bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Mutual Information Calculation\n",
    "The **mutual_info_regression** method was used to identify nonlinear relationships between attributes and the target variable **oximetry**. A higher MI value indicates a stronger (not necessarily linear) relationship.  "
   ],
   "id": "91a8f491b13e8abe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cmp_simple = pd.concat([\n",
    "    corr_sorted.drop('oximetry', errors='ignore').abs().rename('|r|'),\n",
    "    anova_results.set_index('Feature')['F_value'].rename('ANOVA_F'),\n",
    "    scores.rename('Mutual_Info')\n",
    "], axis=1)\n",
    "\n",
    "norm = (cmp_simple - cmp_simple.min()) / (cmp_simple.max() - cmp_simple.min())\n",
    "\n",
    "final_display = (norm.assign(Mean_Score=norm.mean(axis=1)).sort_values('Mean_Score', ascending=False))\n",
    "\n",
    "display(cmp_simple.sort_values('|r|', ascending=False))\n",
    "display(final_display.style.format('{:.6f}'))"
   ],
   "id": "8593604a94478152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Normalisation of values\n",
    "Since individual metrics (Pearson, ANOVA, MI) have different ranges of values,\n",
    "they were normalised using **minimum-maximum scaling** to the interval ⟨0, 1⟩."
   ],
   "id": "dfb6688250a89914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 B",
   "id": "8891a6a7b14809ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ranking of identified attributes by importance\n",
    "\n",
    "All analysed attributes were ranked by their combined **Mean_Score**,\n",
    "which was obtained as the average of the normalised values of three different methods:\n",
    "Pearson |r|, ANOVA F, and Mutual Information.\n",
    "This made it possible to determine the relative importance of each attribute\n",
    "in relation to the target variable **oximetry**.\n",
    "\n",
    "The table above shows the complete ranking of all attributes,\n",
    "where a higher **Mean_Score** value indicates greater attribute significance.\n",
    "For better visualisation, the 5 attributes with the highest scores are shown separately below."
   ],
   "id": "afbd2322bcd9491f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ranked_f = final_display.sort_values('Mean_Score', ascending=False).head(5).copy()\n",
    "display(ranked_f.style.format('{:.6f}'))\n",
    "\n",
    "topk = (final_display.reset_index().head(5))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=topk, x='Mean_Score', y='index')\n",
    "plt.show()"
   ],
   "id": "94505a29fea4290a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 C\n",
    "### Justification of decisions during implementation\n",
    "\n",
    "When solving the problem, we used three approaches to assess the importance of attributes:\n",
    "**Pearson's correlation**, **ANOVA F-test**, and **Mutual Information**.  \n",
    "These three methods provide different insights into how the input variables are related to the target variable *oximetry*:\n",
    "\n",
    "**Pearson's correlation** reflects the linear relationship between the attribute and the target.  \n",
    "\n",
    "**ANOVA F-test** determines whether there are significant differences in the mean values between groups of values.\n",
    "\n",
    "**Mutual information** shows how much information one attribute provides about another, i.e. it also reveals non-linear relationships.\n",
    "\n",
    "By combining these three methods, I was able to compare linear and nonlinear relationships\n",
    "and get a better idea of which attributes are most important for the task.\n",
    "\n",
    "I then **normalised the results using min–max transformation** to the interval ⟨0, 1⟩,\n",
    "so that values from different methods with different ranges could be compared.  \n",
    "From these normalised values, I calculated the **Mean Score**,\n",
    "which shows the overall importance of each attribute.\n",
    "\n",
    "This approach helped me compare the results from several points of view,\n",
    "eliminate differences in scales, and obtain a clear order of attributes depending on their influence on the *oximetry* variable."
   ],
   "id": "55aecaeccb227a9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 A ",
   "id": "3ad9ab6629ec17ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "num_imputer.fit(X_train)\n",
    "\n",
    "X_train_imp = num_imputer.transform(X_train)\n",
    "X_test_imp  = num_imputer.transform(X_test)\n",
    "\n",
    "power = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "power.fit(X_train_imp)\n",
    "\n",
    "X_train_pt = power.transform(X_train_imp)\n",
    "X_test_pt  = power.transform(X_test_imp)"
   ],
   "id": "aa70ea344777cc0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 B\n",
   "id": "26d846f73af9ee05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = make_pipeline(SimpleImputer(strategy=\"median\"), QuantileTransformer(output_distribution='normal', random_state=42), Ridge(random_state=42))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"R^2 test: {r2:.4f}\")\n",
    "\n",
    "y_pred_all = model.predict(X_test)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_all))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_all))\n"
   ],
   "id": "6c66c422daa44ae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The model achieved R² = 0.4719, which means that it explains about 47% of the variability in the target variable of oximetry.\n",
    "It is not perfect, but it shows that the model reflects a significant portion of the relationships in the data.\n",
    "The average error MAE = 0.288 means that the predictions differ from the actual values by an average of approximately 0.29,\n",
    "which is acceptable for health data.\n",
    "MSE = 0.126 confirms that most predictions are relatively close to the correct values.\n",
    "Overall, the model predicts fairly well, and the result can be considered a moderately good basis for further improvement."
   ],
   "id": "b2ddb680f640c820"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
